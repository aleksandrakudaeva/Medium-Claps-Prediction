{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chris McCormick and Nick Ryan. (2019, July 22). BERT Fine-Tuning Tutorial with PyTorch. Retrieved from http://www.mccormickml.com"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import KBinsDiscretizer as KBins\n",
    "import torch\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define device (CPU or GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device_name = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "device = torch.device(device_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loading "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "66380\n",
      "65733\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('train_pro.csv')\n",
    "print(len(train))\n",
    "train = train[train['Claps'] < 2500]\n",
    "print(len(train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train[\"Header\"]\n",
    "y = train['Claps']\n",
    "\n",
    "\n",
    "# Reformat nan values in X\n",
    "X = [str(i) if i != None else 'nan' for i in X]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tried out different binning methods like quantiles and kmeans, but decided for a custom one"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Bin the values of claps\n",
    "target = y.values.reshape(len(y),1)\n",
    "b = KBins(n_bins=10, encode='ordinal', strategy='kmeans')\n",
    "\n",
    "y_bin = b.fit_transform(target)\n",
    "\n",
    "df = pd.DataFrame(zip(y, y_bin.flatten().astype(int)), columns = ['y','y_bin'])\n",
    "df.groupby('y_bin').agg({'y': [min, max, len]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholds = [0, 20, 50, 100, 200, 500, max(y)]\n",
    "#labs = ['0+','20+','50+','100+','200+','500+']\n",
    "labs = [0,1,2,3,4,5]\n",
    "y_bin = torch.LongTensor(pd.cut(y, bins = thresholds, labels = labs, include_lowest=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 0, 0,  ..., 5, 1, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load pretrained Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-vocab.txt from cache at C:\\Users\\MSDesktop/.cache\\torch\\transformers\\26bc1ad6c0ac742e9b52263248f6d0f00068293b33709fae12320c0e35ccfbbb.542ce4285a40d23a559526243235df47c5f75c197f04f37d1a0c124c32c9a084\n",
      "loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-uncased-config.json from cache at C:\\Users\\MSDesktop/.cache\\torch\\transformers\\4dad0251492946e18ac39290fcfe91b89d370fee250efe9521476438fe8ca185.7156163d5fdc189c3016baca0775ffce230789d7fa2a42ef516483e4ca884517\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n",
      "loading weights file https://cdn.huggingface.co/bert-base-uncased-pytorch_model.bin from cache at C:\\Users\\MSDesktop/.cache\\torch\\transformers\\f2ee78bdd635b758cc0a12352586868bef80e47401abe4c4fcc3832421e7338b.36ca03ab34a1a5d5fa7bc3d03d55c4fa650fed07220e2eeebc06ce58d0e9a157\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "\n",
    "\n",
    "# Load the BERT tokenizer.\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
    "\n",
    "# Load pretrained BERT model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels = 6)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenize the sentences in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████| 65733/65733 [00:13<00:00, 5037.14it/s]\n",
      "<ipython-input-23-64f7885db163>:36: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  labels = torch.tensor(y_bin)\n"
     ]
    }
   ],
   "source": [
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "\n",
    "\n",
    "# For every sentence...\n",
    "for sent in tqdm(X):\n",
    "    # `encode_plus` will:\n",
    "    #   (1) Tokenize the sentence.\n",
    "    #   (2) Prepend the `[CLS]` token to the start.\n",
    "    #   (3) Append the `[SEP]` token to the end.\n",
    "    #   (4) Map tokens to their IDs.\n",
    "    #   (5) Pad or truncate the sentence to `max_length`\n",
    "    #   (6) Create attention masks for [PAD] tokens.\n",
    "\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 40,           # Pad & truncate all sentences.\n",
    "                        truncation=True,\n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    # Add the encoded sentence to the list.    \n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "\n",
    "    # And its attention mask (simply differentiates padding from non-padding).\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.tensor(y_bin)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train - Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46,013 training samples\n",
      "19,720 validation samples\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, random_split\n",
    "\n",
    "# Combine the training inputs into a TensorDataset.\n",
    "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
    "\n",
    "# Create a 70-30 train-validation split.\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.7 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "\n",
    "# Divide the dataset by randomly selecting samples.\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "print('{:>5,} training samples'.format(train_size))\n",
    "print('{:>5,} validation samples'.format(val_size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initiate Dataloaders and Batching procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "# Create the DataLoaders for our training and validation sets.\n",
    "train_dataloader = DataLoader(\n",
    "            train_dataset,  \n",
    "            sampler = RandomSampler(train_dataset), # Select batches randomly\n",
    "            batch_size = batch_size \n",
    "        )\n",
    "\n",
    "# Create the DataLoaders for validation sets\n",
    "validation_dataloader = DataLoader(\n",
    "            val_dataset, \n",
    "            sampler = SequentialSampler(val_dataset), # Pull out batches sequentially.\n",
    "            batch_size = batch_size \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(),\n",
    "                  lr = 2e-5, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "                  eps = 1e-8 # args.adam_epsilon  - default is 1e-8.\n",
    "                )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs. The BERT authors recommend between 2 and 4. \n",
    "# After running training procedure for several times with 4 epochs, we saw that there are signs of overfitting\n",
    "epochs = 2\n",
    "\n",
    "# Total number of training steps is [number of batches] x [number of epochs]. \n",
    "# (Note that this is not the same as the number of training samples).\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Function to calculate the accuracy of our predictions vs labels\n",
    "def flat_accuracy(preds, labels):\n",
    "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
    "    labels_flat = labels.flatten()\n",
    "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
    "\n",
    "def format_time(elapsed):\n",
    "    '''\n",
    "    Takes a time in seconds and returns a string hh:mm:ss\n",
    "    '''\n",
    "    # Round to the nearest second.\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  1,438.    Time: 0:00:11.\n",
      "  Batch    80  of  1,438.    Time: 0:00:22.\n",
      "  Batch   120  of  1,438.    Time: 0:00:33.\n",
      "  Batch   160  of  1,438.    Time: 0:00:44.\n",
      "  Batch   200  of  1,438.    Time: 0:00:54.\n",
      "  Batch   240  of  1,438.    Time: 0:01:05.\n",
      "  Batch   280  of  1,438.    Time: 0:01:16.\n",
      "  Batch   320  of  1,438.    Time: 0:01:27.\n",
      "  Batch   360  of  1,438.    Time: 0:01:37.\n",
      "  Batch   400  of  1,438.    Time: 0:01:48.\n",
      "  Batch   440  of  1,438.    Time: 0:01:59.\n",
      "  Batch   480  of  1,438.    Time: 0:02:10.\n",
      "  Batch   520  of  1,438.    Time: 0:02:20.\n",
      "  Batch   560  of  1,438.    Time: 0:02:31.\n",
      "  Batch   600  of  1,438.    Time: 0:02:42.\n",
      "  Batch   640  of  1,438.    Time: 0:02:53.\n",
      "  Batch   680  of  1,438.    Time: 0:03:03.\n",
      "  Batch   720  of  1,438.    Time: 0:03:14.\n",
      "  Batch   760  of  1,438.    Time: 0:03:25.\n",
      "  Batch   800  of  1,438.    Time: 0:03:36.\n",
      "  Batch   840  of  1,438.    Time: 0:03:46.\n",
      "  Batch   880  of  1,438.    Time: 0:03:57.\n",
      "  Batch   920  of  1,438.    Time: 0:04:08.\n",
      "  Batch   960  of  1,438.    Time: 0:04:18.\n",
      "  Batch 1,000  of  1,438.    Time: 0:04:29.\n",
      "  Batch 1,040  of  1,438.    Time: 0:04:40.\n",
      "  Batch 1,080  of  1,438.    Time: 0:04:50.\n",
      "  Batch 1,120  of  1,438.    Time: 0:05:01.\n",
      "  Batch 1,160  of  1,438.    Time: 0:05:12.\n",
      "  Batch 1,200  of  1,438.    Time: 0:05:23.\n",
      "  Batch 1,240  of  1,438.    Time: 0:05:33.\n",
      "  Batch 1,280  of  1,438.    Time: 0:05:44.\n",
      "  Batch 1,320  of  1,438.    Time: 0:05:55.\n",
      "  Batch 1,360  of  1,438.    Time: 0:06:05.\n",
      "  Batch 1,400  of  1,438.    Time: 0:06:16.\n",
      "\n",
      "  Average training loss: 1.25\n",
      "  Training epcoh took: 0:06:26\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.62\n",
      "  Validation Loss: 1.22\n",
      "  Validation took: 0:00:38\n",
      "\n",
      "======== Epoch 2 / 2 ========\n",
      "Training...\n",
      "  Batch    40  of  1,438.    Time: 0:00:09.\n",
      "  Batch    80  of  1,438.    Time: 0:00:18.\n",
      "  Batch   120  of  1,438.    Time: 0:00:28.\n",
      "  Batch   160  of  1,438.    Time: 0:00:37.\n",
      "  Batch   200  of  1,438.    Time: 0:00:46.\n",
      "  Batch   240  of  1,438.    Time: 0:00:55.\n",
      "  Batch   280  of  1,438.    Time: 0:01:04.\n",
      "  Batch   320  of  1,438.    Time: 0:01:13.\n",
      "  Batch   360  of  1,438.    Time: 0:01:22.\n",
      "  Batch   400  of  1,438.    Time: 0:01:31.\n",
      "  Batch   440  of  1,438.    Time: 0:01:41.\n",
      "  Batch   480  of  1,438.    Time: 0:01:50.\n",
      "  Batch   520  of  1,438.    Time: 0:01:59.\n",
      "  Batch   560  of  1,438.    Time: 0:02:07.\n",
      "  Batch   600  of  1,438.    Time: 0:02:16.\n",
      "  Batch   640  of  1,438.    Time: 0:02:25.\n",
      "  Batch   680  of  1,438.    Time: 0:02:35.\n",
      "  Batch   720  of  1,438.    Time: 0:02:44.\n",
      "  Batch   760  of  1,438.    Time: 0:02:52.\n",
      "  Batch   800  of  1,438.    Time: 0:03:01.\n",
      "  Batch   840  of  1,438.    Time: 0:03:11.\n",
      "  Batch   880  of  1,438.    Time: 0:03:20.\n",
      "  Batch   920  of  1,438.    Time: 0:03:29.\n",
      "  Batch   960  of  1,438.    Time: 0:03:38.\n",
      "  Batch 1,000  of  1,438.    Time: 0:03:47.\n",
      "  Batch 1,040  of  1,438.    Time: 0:03:56.\n",
      "  Batch 1,080  of  1,438.    Time: 0:04:05.\n",
      "  Batch 1,120  of  1,438.    Time: 0:04:14.\n",
      "  Batch 1,160  of  1,438.    Time: 0:04:23.\n",
      "  Batch 1,200  of  1,438.    Time: 0:04:32.\n",
      "  Batch 1,240  of  1,438.    Time: 0:04:41.\n",
      "  Batch 1,280  of  1,438.    Time: 0:04:50.\n",
      "  Batch 1,320  of  1,438.    Time: 0:04:59.\n",
      "  Batch 1,360  of  1,438.    Time: 0:05:08.\n",
      "  Batch 1,400  of  1,438.    Time: 0:05:17.\n",
      "\n",
      "  Average training loss: 1.18\n",
      "  Training epcoh took: 0:05:25\n",
      "\n",
      "Running Validation...\n",
      "  Accuracy: 0.62\n",
      "  Validation Loss: 1.22\n",
      "  Validation took: 0:00:32\n",
      "\n",
      "Training complete!\n",
      "Total training took 0:13:02 (h:mm:ss)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "# This training code is based on the `run_glue.py` script here:\n",
    "# https://github.com/huggingface/transformers/blob/5bfcd0485ece086ebcbed2d008813037968a9e58/examples/run_glue.py#L128\n",
    "\n",
    "# Set the seed value all over the place to make this reproducible.\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "\n",
    "# We'll store a number of quantities such as training and validation loss, \n",
    "# validation accuracy, and timings.\n",
    "training_stats = []\n",
    "\n",
    "# Measure the total training time for the whole run.\n",
    "total_t0 = time.time()\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_train_loss = 0\n",
    "    # Set model to training mode\n",
    "    model.train()\n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            # Calculate elapsed time in minutes.\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            \n",
    "            # Report progress.\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Time: {:}.'.format(step, len(train_dataloader), elapsed))\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].type('torch.LongTensor').to(device)\n",
    "        \n",
    "        model.zero_grad()        \n",
    "\n",
    "        loss, logits = model(b_input_ids, \n",
    "                             token_type_ids=None, \n",
    "                             attention_mask=b_input_mask, \n",
    "                             labels=b_labels)\n",
    "        \n",
    "        \n",
    "        total_train_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
    "    \n",
    "    # Measure how long this epoch took.\n",
    "    training_time = format_time(time.time() - t0)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
    "        \n",
    "    # ========================================\n",
    "    #               Validation\n",
    "    # ========================================\n",
    "    # After the completion of each training epoch, measure our performance on\n",
    "    # our validation set.\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Put the model in evaluation mode--the dropout layers behave differently\n",
    "    # during evaluation.\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables \n",
    "    total_eval_accuracy = 0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "\n",
    "    # Evaluate data for one epoch\n",
    "    for batch in validation_dataloader:\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_input_mask = batch[1].to(device)\n",
    "        b_labels = batch[2].type('torch.LongTensor').to(device)\n",
    "\n",
    "        with torch.no_grad():        \n",
    "            \n",
    "            (loss, logits) = model(b_input_ids, \n",
    "                                   token_type_ids=None, \n",
    "                                   attention_mask=b_input_mask,\n",
    "                                   labels=b_labels)\n",
    "            \n",
    "        # Accumulate the validation loss.\n",
    "        total_eval_loss += loss.item()\n",
    "\n",
    "        # Move logits and labels to CPU\n",
    "        logits = logits.detach().cpu().numpy()\n",
    "        label_ids = b_labels.to('cpu').numpy()\n",
    "        \n",
    "        # Accumulate current batch accuracy to the total epoch accuracy \n",
    "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
    "        \n",
    "\n",
    "    # Report the final accuracy for this validation run.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "\n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
    "    \n",
    "    # Measure how long the validation run took.\n",
    "    validation_time = format_time(time.time() - t0)\n",
    "    \n",
    "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
    "    print(\"  Validation took: {:}\".format(validation_time))\n",
    "\n",
    "    # Record all statistics from this epoch.\n",
    "    training_stats.append(\n",
    "        {\n",
    "            'epoch': epoch_i + 1,\n",
    "            'Training Loss': avg_train_loss,\n",
    "            'Valid. Loss': avg_val_loss,\n",
    "            'Valid. Accur.': avg_val_accuracy,\n",
    "            'Training Time': training_time,\n",
    "            'Validation Time': validation_time\n",
    "        }\n",
    "    )\n",
    "\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "\n",
    "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Valid. Loss</th>\n",
       "      <th>Valid. Accur.</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Validation Time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epoch</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.25</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0:06:26</td>\n",
       "      <td>0:00:38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.18</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0:05:25</td>\n",
       "      <td>0:00:32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
       "epoch                                                                         \n",
       "1               1.25         1.22           0.62       0:06:26         0:00:38\n",
       "2               1.18         1.22           0.62       0:05:25         0:00:32"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Display floats with two decimal places.\n",
    "pd.set_option('precision', 2)\n",
    "\n",
    "# Create a DataFrame from our training statistics.\n",
    "stats = pd.DataFrame(data=training_stats).set_index('epoch')\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot the learning curve.\n",
    "plt.plot(stats['Training Loss'], 'b-o', label=\"Training\")\n",
    "plt.plot(stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
    "\n",
    "# Label the plot.\n",
    "plt.title(\"Training & Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.xticks([1, 2])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate on test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_data = val_dataset\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n",
    "  true_labels.append(label_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total MCC: 0.098\n"
     ]
    }
   ],
   "source": [
    "# Combine the results across all batches. \n",
    "flat_predictions = np.concatenate(predictions, axis=0)\n",
    "\n",
    "# For each sample, pick the label (0 or 1) with the higher score.\n",
    "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
    "\n",
    "# Combine the correct labels for each batch into a single list.\n",
    "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
    "\n",
    "# Calculate the MCC\n",
    "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
    "\n",
    "print('Total MCC: %.3f' % mcc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    18957\n",
       "4      380\n",
       "5      204\n",
       "3      168\n",
       "2        9\n",
       "1        2\n",
       "Name: Predicted, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(zip(flat_true_labels, flat_predictions), columns = ['True_Label', 'Predicted'])\n",
    "df.Predicted.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    12171\n",
       "2     2068\n",
       "1     1803\n",
       "3     1580\n",
       "4     1203\n",
       "5      895\n",
       "Name: True_Label, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.True_Label.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Apply to the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create sentence and label lists\n",
    "sentences = df.sentence.values\n",
    "labels = df.label.values\n",
    "\n",
    "# Tokenize all of the sentences and map the tokens to thier word IDs.\n",
    "input_ids = []\n",
    "attention_masks = []\n",
    "\n",
    "# tokenize sentences\n",
    "for sent in sentences:\n",
    "    encoded_dict = tokenizer.encode_plus(\n",
    "                        sent,                      # Sentence to encode.\n",
    "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
    "                        max_length = 40,           # Pad & truncate all sentences.\n",
    "                        truncate = True, \n",
    "                        pad_to_max_length = True,\n",
    "                        return_attention_mask = True,   # Construct attn. masks.\n",
    "                        return_tensors = 'pt',     # Return pytorch tensors.\n",
    "                   )\n",
    "\n",
    "    input_ids.append(encoded_dict['input_ids'])\n",
    "    attention_masks.append(encoded_dict['attention_mask'])\n",
    "\n",
    "# Convert the lists into tensors.\n",
    "input_ids = torch.cat(input_ids, dim=0)\n",
    "attention_masks = torch.cat(attention_masks, dim=0)\n",
    "labels = torch.LongTensor(labels)\n",
    "\n",
    "# Set the batch size.  \n",
    "batch_size = 32  \n",
    "\n",
    "# Create the DataLoader.\n",
    "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
    "prediction_sampler = SequentialSampler(prediction_data)\n",
    "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Tracking variables \n",
    "predictions , true_labels = [], []\n",
    "\n",
    "# Predict \n",
    "for batch in prediction_dataloader:\n",
    "  # Add batch to GPU\n",
    "  batch = tuple(t.to(device) for t in batch)\n",
    "  \n",
    "  # Unpack the inputs from our dataloader\n",
    "  b_input_ids, b_input_mask, b_labels = batch\n",
    "  \n",
    "  # Telling the model not to compute or store gradients, saving memory and \n",
    "  # speeding up prediction\n",
    "  with torch.no_grad():\n",
    "      # Forward pass, calculate logit predictions\n",
    "      outputs = model(b_input_ids, token_type_ids=None, \n",
    "                      attention_mask=b_input_mask)\n",
    "\n",
    "  logits = outputs[0]\n",
    "\n",
    "  # Move logits and labels to CPU\n",
    "  logits = logits.detach().cpu().numpy()\n",
    "  label_ids = b_labels.to('cpu').numpy()\n",
    "  \n",
    "  # Store predictions and true labels\n",
    "  predictions.append(logits)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
